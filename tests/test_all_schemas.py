#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""åŒ…æ‹¬çš„ã‚¹ã‚­ãƒ¼ãƒãƒ»ãƒ‘ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆ

è“„ç©ç³»(NL_*)ã¨é€Ÿå ±ç³»(RT_*)ã®å…¨58ãƒ†ãƒ¼ãƒ–ãƒ« (NL_38 + RT_20) ã¨ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
from pathlib import Path

# Windowsã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’å›é¿
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

sys.path.insert(0, str(Path(__file__).parent))

from src.parser.factory import ParserFactory, ALL_RECORD_TYPES
from src.database.sqlite_handler import SQLiteDatabase
from src.database.schema import SchemaManager, SCHEMAS
from src.importer.importer import DataImporter
from src.jvlink.wrapper import JVLinkWrapper
from dotenv import load_dotenv
import os

def test_parsers():
    """å…¨38ãƒ‘ãƒ¼ã‚µãƒ¼ã®å®Ÿè£…ç¢ºèª"""
    print("=" * 70)
    print("ãƒ‘ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    factory = ParserFactory()
    supported = factory.supported_types()

    print(f"\nå®šç¾©æ¸ˆã¿ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: {len(supported)}")

    # å„ãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
    loaded = []
    failed = []

    for rec_type in supported:
        parser = factory.get_parser(rec_type)
        if parser:
            loaded.append(rec_type)
        else:
            failed.append(rec_type)

    print(f"\nâœ“ ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {len(loaded)}/{len(supported)}")
    if loaded:
        print(f"  {', '.join(loaded)}")

    if failed:
        print(f"\nâœ— ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {len(failed)}")
        print(f"  {', '.join(failed)}")

    return len(failed) == 0

def test_schemas():
    """å…¨58ã‚¹ã‚­ãƒ¼ãƒã®ä½œæˆãƒ†ã‚¹ãƒˆ (NL_38 + RT_20)"""
    print("\n" + "=" * 70)
    print("ã‚¹ã‚­ãƒ¼ãƒãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    print(f"\nå®šç¾©æ¸ˆã¿ã‚¹ã‚­ãƒ¼ãƒ: {len(SCHEMAS)}")

    # NL_* ã¨ RT_* ã«åˆ†é¡
    nl_tables = [t for t in SCHEMAS.keys() if t.startswith('NL_')]
    rt_tables = [t for t in SCHEMAS.keys() if t.startswith('RT_')]

    print(f"  è“„ç©ç³» (NL_*): {len(nl_tables)}")
    print(f"  é€Ÿå ±ç³» (RT_*): {len(rt_tables)}")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ä½œæˆ
    db_path = Path("data/test_all_schemas.db")
    if db_path.exists():
        db_path.unlink()

    database = SQLiteDatabase({"path": str(db_path)})
    success = True

    try:
        database.connect()
        schema_mgr = SchemaManager(database)
        results = schema_mgr.create_all_tables()

        created = sum(1 for v in results.values() if v)
        failed = sum(1 for v in results.values() if not v)

        print(f"\nâœ“ ä½œæˆæˆåŠŸ: {created}/{len(SCHEMAS)}")
        if failed > 0:
            print(f"âœ— ä½œæˆå¤±æ•—: {failed}")
            failed_tables = [k for k, v in results.items() if not v]
            print(f"  {', '.join(failed_tables)}")
            success = False

    finally:
        database.disconnect()
        if db_path.exists():
            db_path.unlink()

    return success

def test_data_import():
    """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆï¼ˆè¤‡æ•°data_specï¼‰"""
    print("\n" + "=" * 70)
    print("ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    load_dotenv()
    sid = os.getenv("JVLINK_SID", "JLTSQL")

    # ãƒ†ã‚¹ãƒˆç”¨data_specï¼ˆè»½é‡ãªã‚‚ã®ã‚’é¸æŠï¼‰
    test_specs = [
        ("RACE", "ãƒ¬ãƒ¼ã‚¹è©³ç´°ç³»"),
        ("YSCH", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç³»"),
    ]

    db_path = Path("data/test_import_all.db")
    if db_path.exists():
        db_path.unlink()

    database = SQLiteDatabase({"path": str(db_path)})
    jv = JVLinkWrapper(sid=sid)
    factory = ParserFactory()

    table_stats = {}

    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æº–å‚™
        database.connect()
        schema_mgr = SchemaManager(database)
        schema_mgr.create_all_tables()

        importer = DataImporter(database, batch_size=100)

        # JV-LinkåˆæœŸåŒ–
        result = jv.jv_init()
        if result != 0:
            print(f"âœ— JV-LinkåˆæœŸåŒ–å¤±æ•—: {result}")
            return False

        print(f"âœ“ JV-LinkåˆæœŸåŒ–æˆåŠŸ\n")

        # å„data_specã§ãƒ‡ãƒ¼ã‚¿å–å¾—
        for data_spec, description in test_specs:
            print(f"\n{description} (data_spec={data_spec})")
            print("-" * 60)

            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚ªãƒ¼ãƒ—ãƒ³
            result_code, read_count, download_count, last_timestamp = jv.jv_open(
                data_spec=data_spec,
                fromtime="20240101000000",
                option=1
            )

            print(f"  JVOpen: code={result_code}, read={read_count}")

            if result_code != 0:
                print(f"  âš  ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚ªãƒ¼ãƒ—ãƒ³å¤±æ•—")
                jv.jv_close()
                continue

            # ãƒ¬ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            record_types_found = set()
            total_records = 0
            max_records = 500  # å„data_specã§æœ€å¤§500ä»¶

            for i in range(max_records):
                result_code, data_bytes, filename = jv.jv_read()

                if result_code <= 0:
                    break

                # ãƒ‘ãƒ¼ã‚¹
                record = factory.parse(data_bytes)
                if record:
                    rec_type = record.get('ãƒ¬ã‚³ãƒ¼ãƒ‰ç¨®åˆ¥ID') or record.get('headRecordSpec')
                    if rec_type:
                        record_types_found.add(rec_type)

                    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    if importer.import_single_record(record):
                        total_records += 1

            jv.jv_close()

            print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: {len(record_types_found)} ç¨®é¡")
            print(f"    {', '.join(sorted(record_types_found))}")
            print(f"  ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {total_records} ä»¶")

        # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥çµ±è¨ˆ
        print("\n" + "=" * 70)
        print("ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
        print("=" * 70)

        nl_with_data = []
        rt_with_data = []

        for table_name in sorted(SCHEMAS.keys()):
            try:
                rows = database.fetch_all(f"SELECT COUNT(*) as cnt FROM {table_name}")
                count = rows[0]['cnt'] if rows else 0

                if count > 0:
                    table_stats[table_name] = count
                    if table_name.startswith('NL_'):
                        nl_with_data.append(table_name)
                    else:
                        rt_with_data.append(table_name)
            except Exception:
                pass

        print(f"\nè“„ç©ç³» (NL_*): {len(nl_with_data)}/38 ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿")
        for table in nl_with_data:
            print(f"  {table:20s}: {table_stats[table]:6,} ä»¶")

        print(f"\né€Ÿå ±ç³» (RT_*): {len(rt_with_data)}/20 ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿")
        if rt_with_data:
            for table in rt_with_data:
                print(f"  {table:20s}: {table_stats[table]:6,} ä»¶")
        else:
            print("  (é€Ÿå ±ãƒ‡ãƒ¼ã‚¿ãªã— - è“„ç©ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—)")

        total_records = sum(table_stats.values())
        print(f"\nç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,} ä»¶")
        print(f"ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ãŸãƒ†ãƒ¼ãƒ–ãƒ«: {len(table_stats)}/{len(SCHEMAS)}")

        return True

    except Exception as e:
        print(f"\nâœ— ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        try:
            jv.jv_close()
        except Exception:
            pass
        database.disconnect()

def test_importer_mappings():
    """ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª"""
    print("\n" + "=" * 70)
    print("ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    database = SQLiteDatabase({"path": ":memory:"})
    importer = DataImporter(database)

    # ãƒãƒƒãƒ”ãƒ³ã‚°ç¢ºèª
    mappings = importer._table_map

    print(f"\nå®šç¾©æ¸ˆã¿ãƒãƒƒãƒ”ãƒ³ã‚°: {len(mappings)}")

    nl_mappings = {k: v for k, v in mappings.items() if v.startswith('NL_')}
    rt_mappings = {k: v for k, v in mappings.items() if v.startswith('RT_')}

    print(f"  è“„ç©ç³» (NL_*): {len(nl_mappings)}")
    print(f"  é€Ÿå ±ç³» (RT_*): {len(rt_mappings)}")

    # ã‚¹ã‚­ãƒ¼ãƒã¨ã®æ•´åˆæ€§ç¢ºèª
    print("\nã‚¹ã‚­ãƒ¼ãƒã¨ã®æ•´åˆæ€§ç¢ºèª:")
    unmapped_nl = []
    unmapped_rt = []

    for table_name in SCHEMAS.keys():
        found = False
        for mapped_table in mappings.values():
            if mapped_table == table_name:
                found = True
                break

        if not found:
            if table_name.startswith('NL_'):
                unmapped_nl.append(table_name)
            else:
                unmapped_rt.append(table_name)

    if unmapped_nl or unmapped_rt:
        print(f"  âš  ãƒãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©ãƒ†ãƒ¼ãƒ–ãƒ«:")
        if unmapped_nl:
            print(f"    NL_*: {', '.join(unmapped_nl)}")
        if unmapped_rt:
            print(f"    RT_*: {', '.join(unmapped_rt)}")
    else:
        print(f"  âœ“ å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°æ¸ˆã¿")

    return True

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("JLTSQLã‚·ã‚¹ãƒ†ãƒ åŒ…æ‹¬ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    results = {}

    # 1. ãƒ‘ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆ
    results['parsers'] = test_parsers()

    # 2. ã‚¹ã‚­ãƒ¼ãƒãƒ†ã‚¹ãƒˆ
    results['schemas'] = test_schemas()

    # 3. ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    results['mappings'] = test_importer_mappings()

    # 4. å®Ÿãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
    results['import'] = test_data_import()

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)

    for test_name, success in results.items():
        status = "âœ“ PASS" if success else "âœ— FAIL"
        print(f"  {test_name:15s}: {status}")

    all_passed = all(results.values())

    if all_passed:
        print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼ï¼")
        return 0
    else:
        print("\nâš  ä¸€éƒ¨ãƒ†ã‚¹ãƒˆå¤±æ•—")
        return 1

if __name__ == "__main__":
    sys.exit(main())
